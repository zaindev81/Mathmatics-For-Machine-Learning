# Mathematics-For-Machine-Learning

機械学習を理解するために必要な数学を学ぶリポジトリです。

## 📁 フォルダ構成

```
Mathematics-For-Machine-Learning/
├── notebooks/          # Jupyterノートブック（実装と可視化）
│   ├── 01_linear_algebra/      # 線形代数のノートブック
│   ├── 02_calculus/            # 微分積分のノートブック
│   ├── 03_probability_statistics/  # 確率統計のノートブック
│   └── 04_optimization/        # 最適化理論のノートブック
│
├── theory/             # 理論と説明（Markdown形式）
│   ├── linear_algebra/         # 線形代数の理論
│   ├── calculus/               # 微分積分の理論
│   ├── probability_statistics/ # 確率統計の理論
│   ├── optimization/           # 最適化理論
│   └── basics_japanese.md      # 基礎数学（日本語）
│
├── exercises/          # 練習問題
│   ├── problems/               # 問題集
│   └── solutions/              # 解答
│
├── code/               # Pythonコード例
│   ├── linear_algebra/         # 線形代数の実装例
│   ├── calculus/               # 微分積分の実装例
│   ├── probability_statistics/ # 確率統計の実装例
│   └── optimization/           # 最適化アルゴリズムの実装例
│
├── resources/          # 参考資料、リンク、参考文献
├── data/              # データセット（必要に応じて）
└── README.md          # このファイル
```

## 🎯 学習の進め方

1. **理論を読む**: `theory/` フォルダで各トピックの理論を学習
2. **コードを実行**: `notebooks/` または `code/` で実装を確認
3. **問題を解く**: `exercises/` で理解度を確認
4. **応用する**: 機械学習アルゴリズムへの応用を理解

## 🚀 セットアップ

```sh
# Jupyter Notebookを起動
jupyter notebook

# または JupyterLabを使用
jupyter lab
```

## 📚 主要なトピック

- **線形代数**: ベクトル、行列、固有値・固有ベクトル、特異値分解
- **微分積分**: 微分、偏微分、勾配、積分、最適化
- **確率統計**: 確率分布、統計量、ベイズ統計、仮説検定
- **最適化**: 勾配降下法、確率的勾配降下法、制約付き最適化

## 🤝 貢献

このリポジトリは学習用です。改善提案や追加コンテンツを歓迎します。
