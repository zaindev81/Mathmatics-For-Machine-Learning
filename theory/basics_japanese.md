# 機械学習のための基礎数学

## 目次
1. [四則演算](#四則演算)
2. [代数](#代数)
3. [関数](#関数)
4. [幾何学](#幾何学)
5. [線形代数の基礎](#線形代数の基礎)
6. [微分積分の基礎](#微分積分の基礎)
7. [確率統計の基礎](#確率統計の基礎)

---

## 四則演算（しそくえんざん）

### 基本的な演算

**加法（かほう） - 足し算**
- 記号: `+`
- 例: `3 + 5 = 8`
- 性質: 交換法則 `a + b = b + a`

**減法（げんぽう） - 引き算**
- 記号: `-`
- 例: `10 - 4 = 6`
- 性質: `a - b = a + (-b)`

**乗法（じょうほう） - 掛け算**
- 記号: `×` または `*`
- 例: `4 × 3 = 12`
- 性質:
  - 交換法則: `a × b = b × a`
  - 分配法則: `a × (b + c) = a × b + a × c`

**除法（じょほう） - 割り算**
- 記号: `÷` または `/`
- 例: `12 ÷ 3 = 4`
- 性質: `a ÷ b = a × (1/b)`

### 演算の優先順位
1. 括弧内の計算
2. 累乗
3. 乗法・除法
4. 加法・減法

---

## 代数（だいすう）

### 変数と定数

**変数（へんすう）**
- 値が変化する数
- 通常、`x`, `y`, `z` などの文字で表す
- 例: `x = 5`, `y = 2x + 3`

**定数（ていすう）**
- 値が固定されている数
- 例: `π ≈ 3.14159`, `e ≈ 2.71828`

### 方程式（ほうていしき）

**一次方程式**
- 形式: `ax + b = 0` (a ≠ 0)
- 解: `x = -b/a`
- 例: `2x + 3 = 7` → `x = 2`

**二次方程式**
- 形式: `ax² + bx + c = 0` (a ≠ 0)
- 解の公式:
  ```
  x = (-b ± √(b² - 4ac)) / 2a
  ```
- 判別式: `D = b² - 4ac`
  - `D > 0`: 異なる2つの実数解
  - `D = 0`: 重解
  - `D < 0`: 異なる2つの虚数解

### 不等式（ふとうしき）

**一次不等式**
- 例: `2x + 3 > 7` → `x > 2`
- 注意: 負の数を掛けたり割ったりするときは不等号の向きが変わる

---

## 関数（かんすう）

### 関数の定義

**関数（function）**
- 入力 `x` に対して、出力 `y` が一意に決まる関係
- 記号: `y = f(x)`
- 定義域: 関数が定義される `x` の範囲
- 値域: 関数が取り得る `y` の範囲

### 基本的な関数

**一次関数（線形関数）**
- 形式: `f(x) = ax + b`
- グラフ: 直線
- 例: `f(x) = 2x + 1`

**二次関数**
- 形式: `f(x) = ax² + bx + c` (a ≠ 0)
- グラフ: 放物線
- 例: `f(x) = x² - 4x + 3`

**指数関数（しすうかんすう）**
- 形式: `f(x) = aˣ` (a > 0, a ≠ 1)
- 例: `f(x) = 2ˣ`, `f(x) = eˣ`

**対数関数（たいすうかんすう）**
- 形式: `f(x) = logₐ(x)` (a > 0, a ≠ 1)
- 性質: `logₐ(xy) = logₐ(x) + logₐ(y)`
- 例: `f(x) = log₂(x)`, `f(x) = ln(x)` (自然対数)

**三角関数（さんかくかんすう）**
- `sin(x)`: 正弦関数
- `cos(x)`: 余弦関数
- `tan(x)`: 正接関数
- 周期関数: `sin(x + 2π) = sin(x)`

---

## 幾何学（きかがく）

### 基本的な図形

**点（てん）**
- 位置を表す
- 座標: `(x, y)`

**直線（ちょくせん）**
- 一次関数のグラフ
- 傾き: `m = (y₂ - y₁)/(x₂ - x₁)`
- 切片: `y = mx + b` の `b`

**円（えん）**
- 中心 `(a, b)`, 半径 `r` の円の方程式:
  ```
  (x - a)² + (y - b)² = r²
  ```

**三角形（さんかくけい）**
- 面積: `S = (1/2) × 底辺 × 高さ`
- ピタゴラスの定理: `a² + b² = c²` (直角三角形)

**距離の公式**
- 2点間の距離:
  ```
  d = √((x₂ - x₁)² + (y₂ - y₁)²)
  ```

---

## 線形代数の基礎（せんけいだいすう）

### ベクトル（vector）

**ベクトルの定義**
- 大きさと方向を持つ量
- 記号: `v = [v₁, v₂, ..., vₙ]`
- 例: `v = [3, 4]` (2次元ベクトル)

**ベクトルの演算**
- 加法: `u + v = [u₁ + v₁, u₂ + v₂, ...]`
- スカラー倍: `cv = [cv₁, cv₂, ...]`
- 内積: `u · v = u₁v₁ + u₂v₂ + ... + uₙvₙ`

**ベクトルの大きさ（ノルム）**
- `||v|| = √(v₁² + v₂² + ... + vₙ²)`

### 行列（matrix）

**行列の定義**
- 数値を縦横に並べたもの
- 例:
  ```
  A = [a₁₁  a₁₂]
      [a₂₁  a₂₂]
  ```

**行列の演算**
- 加法: 対応する要素を足す
- スカラー倍: 各要素にスカラーを掛ける
- 行列の積: `C = AB` (Aの列数 = Bの行数)

**転置行列（てんちぎょうれつ）**
- 行と列を入れ替えた行列
- 記号: `Aᵀ`

**単位行列（たんいぎょうれつ）**
- 対角成分が1、それ以外が0の行列
- 記号: `I`

---

## 微分積分の基礎（びぶんせきぶん）

### 微分（びぶん）

**導関数（どうかんすう）**
- 関数の変化率を表す
- 記号: `f'(x)` または `df/dx`
- 定義:
  ```
  f'(x) = lim(h→0) [f(x+h) - f(x)] / h
  ```

**基本的な微分公式**
- `d/dx(xⁿ) = nxⁿ⁻¹`
- `d/dx(eˣ) = eˣ`
- `d/dx(ln(x)) = 1/x`
- `d/dx(sin(x)) = cos(x)`
- `d/dx(cos(x)) = -sin(x)`

**合成関数の微分（連鎖律）**
- `d/dx(f(g(x))) = f'(g(x)) · g'(x)`

**偏微分（へんびぶん）**
- 多変数関数の一つの変数についての微分
- 記号: `∂f/∂x`

### 積分（せきぶん）

**不定積分（ふていせきぶん）**
- 微分の逆演算
- 記号: `∫f(x)dx`
- 例: `∫x²dx = (1/3)x³ + C` (Cは積分定数)

**定積分（ていせきぶん）**
- 区間 `[a, b]` での積分
- 記号: `∫[a→b] f(x)dx`
- 意味: 関数とx軸で囲まれた面積

**基本的な積分公式**
- `∫xⁿdx = xⁿ⁺¹/(n+1) + C` (n ≠ -1)
- `∫eˣdx = eˣ + C`
- `∫(1/x)dx = ln|x| + C`

---

## 確率統計の基礎（かくりつとうけい）

### 確率（かくりつ）

**確率の定義**
- 事象が起こる可能性の度合い
- 範囲: `0 ≤ P(A) ≤ 1`
- `P(A) = 1`: 必ず起こる
- `P(A) = 0`: 決して起こらない

**基本的な確率の法則**
- 和の法則: `P(A ∪ B) = P(A) + P(B) - P(A ∩ B)`
- 積の法則: `P(A ∩ B) = P(A) · P(B|A)` (条件付き確率)
- 独立事象: `P(A ∩ B) = P(A) · P(B)`

**条件付き確率（じょうけんつきかくりつ）**
- `P(B|A) = P(A ∩ B) / P(A)`
- ベイズの定理:
  ```
  P(A|B) = P(B|A) · P(A) / P(B)
  ```

### 統計（とうけい）

**平均値（へいきんち）**
- 算術平均: `μ = (x₁ + x₂ + ... + xₙ) / n`
- 記号: `μ` (母平均), `x̄` (標本平均)

**分散（ぶんさん）**
- データの散らばり具合
- 定義: `σ² = E[(X - μ)²]`
- 標本分散: `s² = Σ(xᵢ - x̄)² / (n-1)`

**標準偏差（ひょうじゅんへんさ）**
- 分散の平方根
- `σ = √σ²`

**正規分布（せいきぶんぷ）**
- 確率密度関数:
  ```
  f(x) = (1/√(2πσ²)) · exp(-(x-μ)²/(2σ²))
  ```
- 記号: `N(μ, σ²)`

---

## 機械学習への応用

### 重要な数学的概念

1. **勾配降下法（こうばいこうかほう）**
   - 損失関数を最小化するための最適化手法
   - 微分を使用: `θ = θ - α · ∇J(θ)`

2. **線形回帰（せんけいかいき）**
   - `y = w₁x₁ + w₂x₂ + ... + wₙxₙ + b`
   - 最小二乗法でパラメータを推定

3. **確率的勾配降下法（SGD）**
   - データの一部を使って勾配を計算
   - 計算効率が良い

4. **正則化（せいそくか）**
   - L1正則化: `||w||₁`
   - L2正則化: `||w||₂²`

---

## まとめ

機械学習を理解するためには、以下の数学的基礎が重要です：

- ✅ 基本的な代数と関数
- ✅ 線形代数（ベクトル、行列）
- ✅ 微分積分（特に偏微分）
- ✅ 確率統計（確率分布、統計量）

これらの基礎をしっかりと理解することで、機械学習アルゴリズムの原理を深く理解できるようになります。

